{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RD_Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing_Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16534920</td>\n",
       "      <td>13689780</td>\n",
       "      <td>47178410</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>19226183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16259770</td>\n",
       "      <td>15137759</td>\n",
       "      <td>44389853</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>19179206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15344151</td>\n",
       "      <td>10114555</td>\n",
       "      <td>40793454</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>19105039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14437241</td>\n",
       "      <td>11867185</td>\n",
       "      <td>38319962</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>18290199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14210734</td>\n",
       "      <td>9139177</td>\n",
       "      <td>36616842</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>16618794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13187690</td>\n",
       "      <td>9981471</td>\n",
       "      <td>36286136</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>15699112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13461546</td>\n",
       "      <td>14719887</td>\n",
       "      <td>12771682</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>15612251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13029813</td>\n",
       "      <td>14553006</td>\n",
       "      <td>32387668</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>15575260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12054252</td>\n",
       "      <td>14871895</td>\n",
       "      <td>31161329</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>15221177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12333488</td>\n",
       "      <td>10867917</td>\n",
       "      <td>30498162</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>14975996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10191308</td>\n",
       "      <td>11059411</td>\n",
       "      <td>22916095</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>14612195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10067196</td>\n",
       "      <td>9179061</td>\n",
       "      <td>24974455</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>14425940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9386375</td>\n",
       "      <td>12732038</td>\n",
       "      <td>24983944</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>14158552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9199239</td>\n",
       "      <td>13549507</td>\n",
       "      <td>25266493</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>13430735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11994324</td>\n",
       "      <td>15654742</td>\n",
       "      <td>25651292</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>13260265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11452361</td>\n",
       "      <td>12261684</td>\n",
       "      <td>26177623</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>12991704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7801311</td>\n",
       "      <td>12159755</td>\n",
       "      <td>26434606</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>12699293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9465716</td>\n",
       "      <td>14507758</td>\n",
       "      <td>28257431</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>12537037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9174916</td>\n",
       "      <td>11417579</td>\n",
       "      <td>29491957</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>12426690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8641970</td>\n",
       "      <td>15351411</td>\n",
       "      <td>0</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>12277686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7625386</td>\n",
       "      <td>11386730</td>\n",
       "      <td>29866447</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>11847403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7838947</td>\n",
       "      <td>15377343</td>\n",
       "      <td>29973729</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>11131302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7399456</td>\n",
       "      <td>12278275</td>\n",
       "      <td>30331926</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>11035225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6753253</td>\n",
       "      <td>10575103</td>\n",
       "      <td>30476873</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>10873399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7704401</td>\n",
       "      <td>9928134</td>\n",
       "      <td>14057481</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>10855204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6466471</td>\n",
       "      <td>13955316</td>\n",
       "      <td>13796262</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>10740434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7532887</td>\n",
       "      <td>14413598</td>\n",
       "      <td>13405007</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>10573354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7210760</td>\n",
       "      <td>12786455</td>\n",
       "      <td>35318381</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>10500831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6605152</td>\n",
       "      <td>18264556</td>\n",
       "      <td>11814820</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>10328238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6560548</td>\n",
       "      <td>15303206</td>\n",
       "      <td>10713838</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>10100464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6199448</td>\n",
       "      <td>11564128</td>\n",
       "      <td>9113124</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>9993759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6113638</td>\n",
       "      <td>15270192</td>\n",
       "      <td>8821823</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>9748356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6340886</td>\n",
       "      <td>12921961</td>\n",
       "      <td>4608525</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>9742784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5549395</td>\n",
       "      <td>10305749</td>\n",
       "      <td>21463481</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>9677892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4642607</td>\n",
       "      <td>15769392</td>\n",
       "      <td>21079767</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>9671280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4601402</td>\n",
       "      <td>8504744</td>\n",
       "      <td>20551764</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>9647951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2866376</td>\n",
       "      <td>12705621</td>\n",
       "      <td>20112682</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>9070819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4406995</td>\n",
       "      <td>5128314</td>\n",
       "      <td>19702942</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>8994914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2022959</td>\n",
       "      <td>6594793</td>\n",
       "      <td>18526510</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>8122906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3855851</td>\n",
       "      <td>8298209</td>\n",
       "      <td>17499930</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>8100576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2875433</td>\n",
       "      <td>11854605</td>\n",
       "      <td>17279567</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>7823991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2789292</td>\n",
       "      <td>8471077</td>\n",
       "      <td>16447071</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>7779883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2364093</td>\n",
       "      <td>9618963</td>\n",
       "      <td>14800111</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>7149849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1550573</td>\n",
       "      <td>12738230</td>\n",
       "      <td>3553417</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>6975898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2217774</td>\n",
       "      <td>15480614</td>\n",
       "      <td>2833472</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>6520033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>100023</td>\n",
       "      <td>12415304</td>\n",
       "      <td>190393</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>6492608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>131546</td>\n",
       "      <td>11581621</td>\n",
       "      <td>29711446</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>4949075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>13542692</td>\n",
       "      <td>0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>4255973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>54205</td>\n",
       "      <td>5174315</td>\n",
       "      <td>0</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3567341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>11698380</td>\n",
       "      <td>4517306</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1468140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RD_Spend  Administration  Marketing_Spend      State    Profit\n",
       "0   16534920        13689780         47178410  New Delhi  19226183\n",
       "1   16259770        15137759         44389853  Bangalore  19179206\n",
       "2   15344151        10114555         40793454     Mumbai  19105039\n",
       "3   14437241        11867185         38319962  New Delhi  18290199\n",
       "4   14210734         9139177         36616842     Mumbai  16618794\n",
       "5   13187690         9981471         36286136  New Delhi  15699112\n",
       "6   13461546        14719887         12771682  Bangalore  15612251\n",
       "7   13029813        14553006         32387668     Mumbai  15575260\n",
       "8   12054252        14871895         31161329  New Delhi  15221177\n",
       "9   12333488        10867917         30498162  Bangalore  14975996\n",
       "10  10191308        11059411         22916095     Mumbai  14612195\n",
       "11  10067196         9179061         24974455  Bangalore  14425940\n",
       "12   9386375        12732038         24983944     Mumbai  14158552\n",
       "13   9199239        13549507         25266493  Bangalore  13430735\n",
       "14  11994324        15654742         25651292     Mumbai  13260265\n",
       "15  11452361        12261684         26177623  New Delhi  12991704\n",
       "16   7801311        12159755         26434606  Bangalore  12699293\n",
       "17   9465716        14507758         28257431  New Delhi  12537037\n",
       "18   9174916        11417579         29491957     Mumbai  12426690\n",
       "19   8641970        15351411                0  New Delhi  12277686\n",
       "20   7625386        11386730         29866447  Bangalore  11847403\n",
       "21   7838947        15377343         29973729  New Delhi  11131302\n",
       "22   7399456        12278275         30331926     Mumbai  11035225\n",
       "23   6753253        10575103         30476873     Mumbai  10873399\n",
       "24   7704401         9928134         14057481  New Delhi  10855204\n",
       "25   6466471        13955316         13796262  Bangalore  10740434\n",
       "26   7532887        14413598         13405007     Mumbai  10573354\n",
       "27   7210760        12786455         35318381  New Delhi  10500831\n",
       "28   6605152        18264556         11814820     Mumbai  10328238\n",
       "29   6560548        15303206         10713838  New Delhi  10100464\n",
       "30   6199448        11564128          9113124     Mumbai   9993759\n",
       "31   6113638        15270192          8821823  New Delhi   9748356\n",
       "32   6340886        12921961          4608525  Bangalore   9742784\n",
       "33   5549395        10305749         21463481     Mumbai   9677892\n",
       "34   4642607        15769392         21079767  Bangalore   9671280\n",
       "35   4601402         8504744         20551764  New Delhi   9647951\n",
       "36   2866376        12705621         20112682     Mumbai   9070819\n",
       "37   4406995         5128314         19702942  Bangalore   8994914\n",
       "38   2022959         6594793         18526510  New Delhi   8122906\n",
       "39   3855851         8298209         17499930  Bangalore   8100576\n",
       "40   2875433        11854605         17279567  Bangalore   7823991\n",
       "41   2789292         8471077         16447071     Mumbai   7779883\n",
       "42   2364093         9618963         14800111  Bangalore   7149849\n",
       "43   1550573        12738230          3553417  New Delhi   6975898\n",
       "44   2217774        15480614          2833472  Bangalore   6520033\n",
       "45    100023        12415304           190393  New Delhi   6492608\n",
       "46    131546        11581621         29711446     Mumbai   4949075\n",
       "47         0        13542692                0  Bangalore   4255973\n",
       "48     54205         5174315                0  New Delhi   3567341\n",
       "49         0        11698380          4517306  Bangalore   1468140"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Startup_India.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.65349200e+07,   1.36897800e+07,   4.71784100e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.62597700e+07,   1.51377590e+07,   4.43898530e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.53441510e+07,   1.01145550e+07,   4.07934540e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.44372410e+07,   1.18671850e+07,   3.83199620e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.42107340e+07,   9.13917700e+06,   3.66168420e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.31876900e+07,   9.98147100e+06,   3.62861360e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.34615460e+07,   1.47198870e+07,   1.27716820e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.30298130e+07,   1.45530060e+07,   3.23876680e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.20542520e+07,   1.48718950e+07,   3.11613290e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.23334880e+07,   1.08679170e+07,   3.04981620e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.01913080e+07,   1.10594110e+07,   2.29160950e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00671960e+07,   9.17906100e+06,   2.49744550e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          9.38637500e+06,   1.27320380e+07,   2.49839440e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          9.19923900e+06,   1.35495070e+07,   2.52664930e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.19943240e+07,   1.56547420e+07,   2.56512920e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.14523610e+07,   1.22616840e+07,   2.61776230e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          7.80131100e+06,   1.21597550e+07,   2.64346060e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          9.46571600e+06,   1.45077580e+07,   2.82574310e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          9.17491600e+06,   1.14175790e+07,   2.94919570e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          8.64197000e+06,   1.53514110e+07,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          7.62538600e+06,   1.13867300e+07,   2.98664470e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          7.83894700e+06,   1.53773430e+07,   2.99737290e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          7.39945600e+06,   1.22782750e+07,   3.03319260e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          6.75325300e+06,   1.05751030e+07,   3.04768730e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          7.70440100e+06,   9.92813400e+06,   1.40574810e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          6.46647100e+06,   1.39553160e+07,   1.37962620e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          7.53288700e+06,   1.44135980e+07,   1.34050070e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          7.21076000e+06,   1.27864550e+07,   3.53183810e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          6.60515200e+06,   1.82645560e+07,   1.18148200e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          6.56054800e+06,   1.53032060e+07,   1.07138380e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          6.19944800e+06,   1.15641280e+07,   9.11312400e+06],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          6.11363800e+06,   1.52701920e+07,   8.82182300e+06],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          6.34088600e+06,   1.29219610e+07,   4.60852500e+06],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          5.54939500e+06,   1.03057490e+07,   2.14634810e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          4.64260700e+06,   1.57693920e+07,   2.10797670e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          4.60140200e+06,   8.50474400e+06,   2.05517640e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          2.86637600e+06,   1.27056210e+07,   2.01126820e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          4.40699500e+06,   5.12831400e+06,   1.97029420e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          2.02295900e+06,   6.59479300e+06,   1.85265100e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.85585100e+06,   8.29820900e+06,   1.74999300e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.87543300e+06,   1.18546050e+07,   1.72795670e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          2.78929200e+06,   8.47107700e+06,   1.64470710e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.36409300e+06,   9.61896300e+06,   1.48001110e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.55057300e+06,   1.27382300e+07,   3.55341700e+06],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.21777400e+06,   1.54806140e+07,   2.83347200e+06],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.00023000e+05,   1.24153040e+07,   1.90393000e+05],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.31546000e+05,   1.15816210e+07,   2.97114460e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.35426920e+07,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          5.42050000e+04,   5.17431500e+06,   0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.16983800e+07,   4.51730600e+06]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, 3] = labelencoder.fit_transform(X[:, 3])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   1.00000000e+00,   1.65349200e+07,\n",
       "          1.36897800e+07,   4.71784100e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.62597700e+07,\n",
       "          1.51377590e+07,   4.43898530e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.53441510e+07,\n",
       "          1.01145550e+07,   4.07934540e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.44372410e+07,\n",
       "          1.18671850e+07,   3.83199620e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.42107340e+07,\n",
       "          9.13917700e+06,   3.66168420e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.31876900e+07,\n",
       "          9.98147100e+06,   3.62861360e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.34615460e+07,\n",
       "          1.47198870e+07,   1.27716820e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.30298130e+07,\n",
       "          1.45530060e+07,   3.23876680e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.20542520e+07,\n",
       "          1.48718950e+07,   3.11613290e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.23334880e+07,\n",
       "          1.08679170e+07,   3.04981620e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.01913080e+07,\n",
       "          1.10594110e+07,   2.29160950e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00671960e+07,\n",
       "          9.17906100e+06,   2.49744550e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   9.38637500e+06,\n",
       "          1.27320380e+07,   2.49839440e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   9.19923900e+06,\n",
       "          1.35495070e+07,   2.52664930e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.19943240e+07,\n",
       "          1.56547420e+07,   2.56512920e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.14523610e+07,\n",
       "          1.22616840e+07,   2.61776230e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   7.80131100e+06,\n",
       "          1.21597550e+07,   2.64346060e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   9.46571600e+06,\n",
       "          1.45077580e+07,   2.82574310e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   9.17491600e+06,\n",
       "          1.14175790e+07,   2.94919570e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   8.64197000e+06,\n",
       "          1.53514110e+07,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   7.62538600e+06,\n",
       "          1.13867300e+07,   2.98664470e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   7.83894700e+06,\n",
       "          1.53773430e+07,   2.99737290e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   7.39945600e+06,\n",
       "          1.22782750e+07,   3.03319260e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   6.75325300e+06,\n",
       "          1.05751030e+07,   3.04768730e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   7.70440100e+06,\n",
       "          9.92813400e+06,   1.40574810e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   6.46647100e+06,\n",
       "          1.39553160e+07,   1.37962620e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   7.53288700e+06,\n",
       "          1.44135980e+07,   1.34050070e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   7.21076000e+06,\n",
       "          1.27864550e+07,   3.53183810e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   6.60515200e+06,\n",
       "          1.82645560e+07,   1.18148200e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   6.56054800e+06,\n",
       "          1.53032060e+07,   1.07138380e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   6.19944800e+06,\n",
       "          1.15641280e+07,   9.11312400e+06],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   6.11363800e+06,\n",
       "          1.52701920e+07,   8.82182300e+06],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   6.34088600e+06,\n",
       "          1.29219610e+07,   4.60852500e+06],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   5.54939500e+06,\n",
       "          1.03057490e+07,   2.14634810e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   4.64260700e+06,\n",
       "          1.57693920e+07,   2.10797670e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   4.60140200e+06,\n",
       "          8.50474400e+06,   2.05517640e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   2.86637600e+06,\n",
       "          1.27056210e+07,   2.01126820e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   4.40699500e+06,\n",
       "          5.12831400e+06,   1.97029420e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   2.02295900e+06,\n",
       "          6.59479300e+06,   1.85265100e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   3.85585100e+06,\n",
       "          8.29820900e+06,   1.74999300e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   2.87543300e+06,\n",
       "          1.18546050e+07,   1.72795670e+07],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   2.78929200e+06,\n",
       "          8.47107700e+06,   1.64470710e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   2.36409300e+06,\n",
       "          9.61896300e+06,   1.48001110e+07],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.55057300e+06,\n",
       "          1.27382300e+07,   3.55341700e+06],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   2.21777400e+06,\n",
       "          1.54806140e+07,   2.83347200e+06],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.00023000e+05,\n",
       "          1.24153040e+07,   1.90393000e+05],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.31546000e+05,\n",
       "          1.15816210e+07,   2.97114460e+07],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.35426920e+07,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   5.42050000e+04,\n",
       "          5.17431500e+06,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.16983800e+07,   4.51730600e+06]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avoiding the Dummy Variable Trap\n",
    "X = X[:, 1:]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEQCAYAAACz0c/rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGfZJREFUeJzt3X2MXHd97/H3xw9UMgQS8JbSJLvLRZAQuA0hW0ApommR\nimPUWtUFyWFUQhp15fCgVKqqVFm1+QNtRaU+QBuSaJv6JhFbRy2klCIT6C2X60IIsOaGxCZt6iax\ncUD1JilPcSVk77d/nJl4PDkzc2bmzJyH+byk1e6c85tzvp6cfPe3v0dFBGZmVn+big7AzMwmwwnf\nzGxKOOGbmU0JJ3wzsynhhG9mNiWc8M3MpkShCV/SXkknJB3KUPbPJD3Y/HpU0vcnEaOZWV2oyHH4\nkt4G/Bi4OyJeP8D7PgRcFhG/ObbgzMxqptAafkQcAJ5pPybpVZLuk3RQ0j9LujjlrVcD+yYSpJlZ\nTWwpOoAUK8CeiPg3SW8GbgV+uXVS0hzwSuCLBcVnZlZJpUr4kl4EXAH8raTW4Z/qKLYb+GREnJ5k\nbGZmVVeqhE/SxPT9iHhDjzK7gQ9MKB4zs9oo1bDMiPgh8LikdwMocWnrfLM9/zzgqwWFaGZWWUUP\ny9xHkrwvknRc0nVAA7hO0reAw8CutrfsBu4JL/FpZjawvsMyJV0I3A28HAhgJSI+1lFGwMeAncBJ\n4H0R8c2xRGxmZkPJ0oZ/CvidiPimpHOAg5L+MSK+3VbmKuDVza83A7c1v5uZWUn0TfgR8T3ge82f\nfyTpEeB8oD3h7yKZPBXAA5LOlfSK5ntTbd++Pebn50cK3sxs2hw8ePCpiJgZ5r0DjdKRNA9cBnyt\n49T5wHfaXh9vHjsr4UtaBBYBZmdnWVtbGyxaM7MpJ+nosO/N3GnbHCP/KeC3m6NpBhYRKxGxEBEL\nMzND/YIyM7MhZUr4kraSJPvViLg3pciTwIVtry9oHjMzs5Lom/CbI3D+CngkIv60S7HPAO9tjpt/\nC/CDXu33ZmY2eVna8H8B+A3gYUkPNo/dBMwCRMTtwH6SIZlHSIZlXpt/qGZmNooso3S+DKhPmcDL\nHZiZlVqpllYwM6ut1VWYn4dNm5Lvq6sTD6Fsi6eZmdXP6iosLsLJk8nro0eT1wCNxsTCcA3fzGzc\nlpbOJPuWkyeT4xPkhG9mNm7Hjg12fEyc8M3Mxm12drDjY+KEb2Y2bjt3gjoGO27bBsvLEw3DCd/M\nbJxWV+Guu6B9KXoJrrlmoh224IRvZjZeaR22EbB//8RDccI3MxunknTYghO+mdl4laTDFpzwzczG\na3k56aBtV0CHLTjhm5mNV6MBKyswN5d01s7NJa8n3GELXlrBzGz8Go1CEnwn1/DNzKaEE76Z2ZRw\nwjczmxJO+GZmUyLLnrZ7JZ2QdKjL+ZdI+gdJ35J0WJK3NzQzK6EsNfw7gR09zn8A+HZEXApcCfyJ\npBeMHpqZmeWpb8KPiAPAM72KAOdIEvCiZtlT+YRnZmZ5yaMN/xbgtcB3gYeBGyJiI4frmplVXgm2\nsn1OHgn/HcCDwM8CbwBukfTitIKSFiWtSVpbX1/P4dZmZuXV2sr26NFkgczWVrZFJf08Ev61wL2R\nOAI8DlycVjAiViJiISIWZmZmcri1mVl5lWQr2+fkkfCPAW8HkPRy4CLgsRyua2ZWaSVaGRnIsJaO\npH0ko2+2SzoO3AxsBYiI24EPA3dKehgQcGNEPDW2iM3MKmJ2NmnGSTtehL4JPyKu7nP+u8Cv5BaR\nmVlNLC8nbfbtzToFrYwMeKatmdnYlGhlZMAJ38wsmyHHVzYa8MQTsLGRfC9ylWSvh29m1k9rfGWr\nbaY1vhJKsc59Vq7hm5n1U7bxlUNywjcz66ds4yuH5IRvZtZPt3GURY2vHJITvplZP8vLyXjKdkWO\nrxySE76ZWT9lG185JCd8M6ucQlagLNP4yiF5WKaZVUpNRkgWwjV8M6uUmoyQLIQTvplVSk1GSBbC\nCd/MKqUmIyQL4YRvZpVSkxGShXDCN7NKqckIyUJ4lI6ZVU6j4QQ/DNfwzawYhQymn26u4ZvZ5Hkw\nfSH61vAl7ZV0QtKhHmWulPSgpMOS/l++IZpZ7XgwfSGyNOncCezodlLSucCtwK9FxOuAd+cTmpnV\nlgfTF6Jvwo+IA8AzPYq8B7g3Io41y5/IKTYzq5tWu31E+nkPph+rPDptXwOcJ+lLkg5Kem+3gpIW\nJa1JWltfX8/h1mZWGa12+6NH0897MP3Y5ZHwtwCXA+8E3gH8vqTXpBWMiJWIWIiIhZmZmRxubWaV\nkdZu3+LB9BORxyid48DTEfEs8KykA8ClwKM5XNvM6qJX+/wTT0wsjGmWRw3/74G3StoiaRvwZuCR\nHK5rZnXSrX1e8hj8CckyLHMf8FXgIknHJV0naY+kPQAR8QhwH/AQ8HXgjojoOoTTzKbU8nKS3DtF\neDjmhCi69ZaP2cLCQqytrRVybzMrSFrCbx3f2JhsLBUl6WBELAzzXi+tYGaTMzeXftzDMSfCCd/M\nRte5Ls7735++To7XNi6U19Ixs9GkrYtz221nzqetk7O0lIzamZ1Nkr2HY06E2/DNbDTz890nU7Wb\nm/Pwyxy4Dd/MipN1/Ruvk1M4J3wzG03WDld3zBbOCd+sbia9sUhaR2wnd8yWghO+WZ20L1AWcabD\ndJxJP22T2euv96azJeROW7M66daB6g7T2nCnrZklvLGI9eCEb1Yn3TpG3WFqOOGbVVtnB+3OnZ7J\nal054ZtVVVoH7V13wTXXuMPUUnlpBbOqSttB6uRJ2L/fHbSWyjV8s6pyB60NyAnfrKrcQWsDcsI3\nqyovNWwDcsI3q6q0Ga7uoLUesuxpu1fSCUk996mV9POSTkl6V37hmVlPjUbSQbuxkXx3srcestTw\n7wR29CogaTPwR8AXcojJzMzGoG/Cj4gDwDN9in0I+BRwIo+gzMwsfyO34Us6H/h14LYMZRclrUla\nW19fH/XWZmY2gDw6bT8K3BgRG/0KRsRKRCxExMLMzEwOtzYzs6zymGm7ANwjCWA7sFPSqYj4dA7X\nNjOznIyc8CPila2fJd0JfNbJ3sysfPomfEn7gCuB7ZKOAzcDWwEi4vaxRmdmZrnpm/Aj4uqsF4uI\n940UjZmZjY1n2pqZTQknfDPrqX2Ple3bk6/Wfivj3Bvd8ueEb1Z2nbtaTTDLdu6x8vTTyVdrv5XF\nRSf9KnHCNyuztF2tJphl0/ZYaXfyZFLGqsEJ36zMuu1qNaEsm2UvFe+3Uh1O+GZlVvCuVln2UvF+\nK9XhhG9WZgXvapW2x0o777dSLU74ZmVW8K5WnXusvOxlyZf3W6kmJ3yzslpdPdOGv3lzcmzQLDvo\nCJ+U8u17rDz1VPLl/VaqKY/F08wsb63ROa0O29Onz9TsB0n27ddojfCB9GsMWt4qRxFRyI0XFhZi\nbW2tkHubld78fJJwO83NJVXrcVwjj3va2Ek6GBELw7zXTTpmZZTH6JxBr1HwiCAbPyd8szLKY3TO\noNcoeESQjZ8TvlkZ5TE6Z9BrFDwiyMbPCd+sjDrHQw4zBnLQa+RxTys1d9qamVWIO23NzKwvJ3wz\nsynRN+FL2ivphKRDXc43JD0k6WFJ90u6NP8wzUqswPXqzQaRpYZ/J7Cjx/nHgV+MiP8JfBhYySEu\ns2ooeL16s0H0TfgRcQB4psf5+yPiP5svHwAuyCk2s/IreL16s0Hk3YZ/HfC5biclLUpak7S2vr6e\n863NCuDZqVYhuSV8Sb9EkvBv7FYmIlYiYiEiFmZmZvK6tVlxPDvVKiSXhC/p54A7gF0R8XQe1zQr\nUuZ+2GFmpw7byevOYRtVRPT9AuaBQ13OzQJHgCuyXKv1dfnll4dZGX3iExHbtkUkvbDJ17ZtyfGu\nb5ibi5CS710LZrh4t2sNHJTVFbAWA+Ta9q++M20l7QOuBLYD/wHcDGxt/rK4XdIdwP8CWuuqnooM\ns8A809bKaqyrBPe6+PLy2evRQ/LXwspK0gnspYuN0WbaemkFsw6bNiVV6E5SstNTS2tDqmPHkib7\nTHuT9Lr47Gz3pH7sWLagrPa8tIJZjrL0ww49/L7XxXuN+HHnsOXACd+sQ5Z+2KGH3/e6eK+k7qWL\nLQdO+GYdsqwSPPTw+14X75XUvXSx5cBt+GaDaDbczx/9EkeZf97pkftQh+oYsGniNnyzSWhruF/m\nJrbx7Fmnc2lhaTSS3xgbG8l3J3vLkRO+WTedE51uuOG5hvsG+1jht5jjCcSGW1isEtykY5amVZvv\n7JlN46GRNkFu0jHLW9ownG5e+tLxxmKWEyd8szRe7dJqyAnfLM0gE5qe6bpdhFmpOOGbpUkbEy+l\nl/VsV6sIJ3yzNGkTnfbs8WxXqzQnfLNuOsfE33qrZ7tapW0pOgCzSmk0nOCtslzDt+nVMbFq9f1f\n9oZSVmtO+DadOtY3Xj16BYu3XdZ9uWNvL2g14Jm2Np06dp6a5/Hui6Etp8y6be1E5eYdmzDveGU2\nqI6dpzZxmkj5g1eCjdl5by9opTHWpRUk7ZV0QtKhLucl6c8lHZH0kKQ3DhOI2UR1jJ2fJX1m7ews\nIyx+b1YuWdrw7wR29Dh/FfDq5tcicNvoYZnlJ7X5vWNiVc/ljr29oNVE34QfEQeAXnPHdwF3R+IB\n4FxJr8grQLNRdN17lrMnVjXm7mfl+v+fPsTe2wtaTWRqw5c0D3w2Il6fcu6zwEci4svN1/8E3BgR\nz2ugl7RI8lcAs7Ozlx9Naxc1y1FH3+xzBm5+905UVhKVWR45IlYiYiEiFmZmZiZ5a5tSx46mV2iO\nHd0YbIild6KyGsgj4T8JXNj2+oLmMbPCzW46nn6cY10G3JvVVx4J/zPAe5ujdd4C/CAivpfDdc1G\ns7rK8saNz++M5VmWuenMgZMnk+Yas5rru5aOpH3AlcB2SceBm4GtABFxO7Af2AkcAU4C144rWLOB\nLC3RIGnAX+IPOcYssxxjmZtosO/ssh5iaVPAE6+svjomV/XkSVRWEZXptDWbqKzj5D3E0qaEE77V\nV7fx89df7zXtbSp5PXyrr0YDvvKVJKGfPg2bN8M11yQbmZhNIdfwrb5WV+Guu5JkD8n3u+7yEEyb\nWk74Vl9LS2cvaQwegmlTzQnf6qvb0h0egmlTygnf6ml1NemUTeNVLm1KOeFbPS0tpY/BlzwE06aW\nE77VU7dmmwgPwbSp5YRv9dSt2WZubrJxmJWIE75VS+r2VSm8aYnZ8zjhW3V03b4qJek3zt7RyjNq\nzbx4mlVJbttXmVWXF0+z6dCtI9bj6s0yccK36ujWEetx9WaZOOHb5GXteO3kjlizkTjh22QN0vHa\nyR2xZiPJ1GkraQfwMWAzcEdEfKTj/EuATwCzJEsu/3FE/O9e13Sn7ZRyx6vZSMbaaStpM/Bx4Crg\nEuBqSZd0FPsA8O2IuJRk/9s/kfSCYQKymnPHq1lhsjTpvAk4EhGPRcRPgHuAXR1lAjhHkoAXAc8A\np3KN1OrBHa9mhcmS8M8HvtP2+njzWLtbgNcC3wUeBm6IiI1cIrR6ccerWWHy6rR9B/Ag8LPAG4Bb\nJL24s5CkRUlrktbW19dzurVVijtezQqTJeE/CVzY9vqC5rF21wL3RuII8DhwceeFImIlIhYiYmFm\nZmbYmK3qGo2kg3ZjI/nuZG82EVkS/jeAV0t6ZbMjdjfwmY4yx4C3A0h6OXAR8FiegZqZ2Wj6JvyI\nOAV8EPg88AjwNxFxWNIeSXuaxT4MXCHpYeCfgBsj4qlxBW0VMuwkq0lf02wKePE0G5/WJKv2jcS3\nbRutzX4c1zSrkFHG4Tvh2/iMY5KVJ27ZlPNqmVZO45hk5YlbZkNzwrexWX3pB5nncTZxmnkeZ5Wr\nkxOjTLLyxC2zoTnh21isrsLij/6Uo8wTbOIo8yzyl6xufd9ok6w8cctsaE74NhZLS3DyJ1vOOnaS\nF7L04r8YrXPVE7fMhuZOWxuLTZuS1Y87Scl8KzMbjjttbbIyjIN3U7tZ+Tjh22AybmDipnaz8nHC\nt8EsLZ096QmS10tLZx3q1dTuibJmxXAbvg1mxMZ5T5Q1G43b8G1yRmycz/gHgpmNgRO+JbK2s4zY\nOO+JsmbFccK3zB2xwMjj4D16x6w4bsO3iS5I5jZ8s9G4Dd9GM8F2Fk+UNSvOlv5FrPZmZ9Nr+GNq\nZ2k0nODNiuAavnmWlNmUcMK3bO0sni1lVnmZmnQk7QA+BmwG7oiIj6SUuRL4KLAVeCoifjHHOG3c\nerWzdPa0tkbxtN5nZpXQt4YvaTPwceAq4BLgakmXdJQ5F7gV+LWIeB3w7jHEakXxbCmzWsjSpPMm\n4EhEPBYRPwHuAXZ1lHkPcG9EHAOIiBP5hmmF8mwps1rIkvDPB77T9vp481i71wDnSfqSpIOS3pt2\nIUmLktYkra2vrw8XsU2eZ0uZ1UJenbZbgMuBdwLvAH5f0ms6C0XESkQsRMTCzMxMTreusbJ0lHoU\nj1ktZEn4TwIXtr2+oHms3XHg8xHxbEQ8BRwALs0nxCk1yHIH4+bZUma10HdpBUlbgEeBt5Mk+m8A\n74mIw21lXgvcQlK7fwHwdWB3RBzqdl0vrdDHBJc7MLPqGGVphb7DMiPilKQPAp8nGZa5NyIOS9rT\nPH97RDwi6T7gIWCDZOhm12RvGbij1Mxy5sXTyso1fDNL4cXT6sgdpWaWMyf8snJHqZnlzKtllpmX\nlTSzHLmGb2Y2JZzwzcymhBO+mdmUcMI3M5sS1Ur4ZVlbpm78uZpNheqM0vEmHOPhz9VsalSnhl+H\nTTjKWJOuw+dqZplUp4Zf9bVlylqTrvrnamaZVaeGX8ZNOAapsZe1Jl3Gz9XMxqI6Cb9sa8sMul59\nWWvSZftczWxsqpPwy7a2zKA19rLWpMv2uZrZ2Hh55GFt2pTU7DtJsLHx/OOdbfiQ1KSdXM1sAF4e\nuQiD1thdkzazgjnhD2uYtu9GI9m8ZGMj+e5kb2YT5IQ/LNfYzaxiMiV8STsk/aukI5J+r0e5n5d0\nStK78guxxFxjN7MK6ZvwJW0GPg5cBVwCXC3pki7l/gj4Qt5BmpnZ6LLU8N8EHImIxyLiJ8A9wK6U\nch8CPgWcyDE+MzPLSZaEfz7wnbbXx5vHniPpfODXgdt6XUjSoqQ1SWvr6+uDxmpmZiPIq9P2o8CN\nEZEyAP2MiFiJiIWIWJiZmcnp1mZmlkWWxdOeBC5se31B81i7BeAeSQDbgZ2STkXEp3OJ0szMRtZ3\npq2kLcCjwNtJEv03gPdExOEu5e8EPhsRn+xz3XXg6BAx52k78FTBMWRVlVirEic41nGpSqxViRPO\njnUuIoZqIulbw4+IU5I+CHwe2AzsjYjDkvY0z98+zI2HDThPktaGnaI8aVWJtSpxgmMdl6rEWpU4\nIb9YM62HHxH7gf0dx1ITfUS8b9SgzMwsf55pa2Y2JaY94a8UHcAAqhJrVeIExzouVYm1KnFCTrEW\ntjyymZlN1rTX8M3MpoYTvpnZlKhlwu+3uqekhqSHJD0s6X5Jl7ade6J5/EFJY9+SK0OsV0r6QTOe\nByX9Qdb3FhDr77bFeUjSaUkvbZ6b2Ocqaa+kE5IOdTkvSX/e/Hc8JOmNbecm/Zn2i7VMz2q/WEvx\nrGaIsxTPafN+F0r6v5K+LemwpBtSyuT3vEZErb5I5gr8O/A/gBcA3wIu6ShzBXBe8+ergK+1nXsC\n2F6iWK8kmcg28HsnHWtH+V8FvljQ5/o24I3AoS7ndwKfAwS8pfXff9KfacZYS/GsZoy1LM9qzzg7\nyhb2nDbv9wrgjc2fzyGZ5NqZA3J7XutYw++7umdE3B8R/9l8+QDJchFFyLoSad7vHcag97sa2DfG\neLqKiAPAMz2K7ALujsQDwLmSXsHkP9O+sZboWc3yuXYz0c91wDgLe04BIuJ7EfHN5s8/Ah6hY3FK\ncnxe65jw+67u2eE6kt+eLQH8H0kHJS2OIb52WWO9ovmn3OckvW7A9+Yl8/0kbQN2kCyX3TLJz7Wf\nbv+WSX+mgyryWc2qDM9qJmV7TiXNA5cBX+s4ldvzmmmmbV1J+iWS/4ne2nb4rRHxpKSfBv5R0r80\nawxF+SYwGxE/lrQT+DTw6gLjyeJXga9ERHstq2yfa6X4WR2L0jynkl5E8ovntyPih+O6Tx1r+FlW\n90TSzwF3ALsi4unW8Yh4svn9BPB3JH82FRZrRPwwIn7c/Hk/sFXS9izvnXSsbXbT8WfyhD/Xfrr9\nWyb9mWZSkme1rxI9q1mV4jmVtJUk2a9GxL0pRfJ7XifVOTGpL5K/Wh4DXsmZjozXdZSZBY4AV3Qc\nfyFwTtvP9wM7Co71ZzgzQe5NwDGSzpu+7510rM1yLyFpP31hUZ9r8z7zdO9cfCdnd4J9fZB/44Rj\nLcWzmjHWUjyr/eIs2XMq4G7goz3K5Pa81q5JJ7Kt7vkHwMuAW5Ws4X8qkpXoXg78XfPYFuCvI+K+\ngmN9F3C9pFPAfwG7I/mvnfregmOFZOezL0TEs21vn+jnKmkfyYiR7ZKOAzcDW9vi3E8y8uEIcBK4\ntte/cVxxZoy1FM9qxlhL8axmiBNK8Jw2/QLwG8DDkh5sHruJ5Bd97s+rl1YwM5sSdWzDNzOzFE74\nZmZTwgnfzGxKOOGbmU0JJ3wzswnot6hbR9k/a1vg7VFJ388lBo/SMTMbP0lvA35Msi7O6wd434eA\nyyLiN0eNwTV8M7MJiJRF3SS9StJ9zbV7/lnSxSlvzW2Bt9pNvDIzq5AVYE9E/JukNwO3Ar/cOilp\njmQm7RfzuJkTvplZAZoLpl0B/G1zdi/AT3UU2w18MiJO53FPJ3wzs2JsAr4fEW/oUWY38IE8b2hm\nZhMWyTLIj0t6Nzy3lWH7FpYXA+cBX83rnk74ZmYT0FzU7avARZKOS7oOaADXSfoWcJizd6zaDdwT\nOQ6l9LBMM7Mp4Rq+mdmUcMI3M5sSTvhmZlPCCd/MbEo44ZuZTQknfDOzKeGEb2Y2Jf4b8+7e+uhh\n7EYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa4dad68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(1, figsize=(10, 10),)\n",
    "plt.scatter(y_train,regressor.predict(X_train), color='r')\n",
    "plt.scatter(y_test,regressor.predict(X_test), color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEWCAYAAAA3h9P4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niGQ1BSoREclq/w9d4KhIUEZf2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa178f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import stats as mystats\n",
    "res = regressor.predict(X)-y\n",
    "mystats.probplot(res,plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   169.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 08 Apr 2018</td> <th>  Prob (F-statistic):</th> <td>1.34e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:20:07</td>     <th>  Log-Likelihood:    </th> <td> -755.64</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1523.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1535.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.013e+06</td> <td> 6.88e+05</td> <td>    7.281</td> <td> 0.000</td> <td> 3.62e+06</td> <td>  6.4e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 1.988e+04</td> <td> 3.37e+05</td> <td>    0.059</td> <td> 0.953</td> <td> -6.6e+05</td> <td> 6.99e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-4188.7019</td> <td> 3.26e+05</td> <td>   -0.013</td> <td> 0.990</td> <td> -6.6e+05</td> <td> 6.52e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.369</td> <td> 0.000</td> <td>    0.712</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.517</td> <td> 0.608</td> <td>   -0.132</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.574</td> <td> 0.123</td> <td>   -0.008</td> <td>    0.062</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.782</td> <th>  Durbin-Watson:     </th> <td>   1.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.41e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.572</td> <th>  Cond. No.          </th> <td>1.45e+08</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     169.9\n",
       "Date:                Sun, 08 Apr 2018   Prob (F-statistic):           1.34e-27\n",
       "Time:                        23:20:07   Log-Likelihood:                -755.64\n",
       "No. Observations:                  50   AIC:                             1523.\n",
       "Df Residuals:                      44   BIC:                             1535.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.013e+06   6.88e+05      7.281      0.000    3.62e+06     6.4e+06\n",
       "x1          1.988e+04   3.37e+05      0.059      0.953    -6.6e+05    6.99e+05\n",
       "x2         -4188.7019   3.26e+05     -0.013      0.990    -6.6e+05    6.52e+05\n",
       "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
       "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
       "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
       "==============================================================================\n",
       "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
       "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
       "Kurtosis:                       5.572   Cond. No.                     1.45e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.45e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the optimal model using Backward Elimination\n",
    "import statsmodels.formula.api as sm\n",
    "X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 08 Apr 2018</td> <th>  Prob (F-statistic):</th> <td>8.49e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:20:07</td>     <th>  Log-Likelihood:    </th> <td> -755.64</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1521.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1531.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.011e+06</td> <td> 6.65e+05</td> <td>    7.537</td> <td> 0.000</td> <td> 3.67e+06</td> <td> 6.35e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 2.202e+04</td> <td>  2.9e+05</td> <td>    0.076</td> <td> 0.940</td> <td>-5.62e+05</td> <td> 6.06e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.8060</td> <td>    0.046</td> <td>   17.606</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0270</td> <td>    0.052</td> <td>   -0.523</td> <td> 0.604</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0270</td> <td>    0.017</td> <td>    1.592</td> <td> 0.118</td> <td>   -0.007</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.758</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.948</td> <th>  Prob(JB):          </th> <td>2.53e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.563</td> <th>  Cond. No.          </th> <td>1.40e+08</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Sun, 08 Apr 2018   Prob (F-statistic):           8.49e-29\n",
       "Time:                        23:20:07   Log-Likelihood:                -755.64\n",
       "No. Observations:                  50   AIC:                             1521.\n",
       "Df Residuals:                      45   BIC:                             1531.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.011e+06   6.65e+05      7.537      0.000    3.67e+06    6.35e+06\n",
       "x1          2.202e+04    2.9e+05      0.076      0.940   -5.62e+05    6.06e+05\n",
       "x2             0.8060      0.046     17.606      0.000       0.714       0.898\n",
       "x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n",
       "x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
       "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
       "Kurtosis:                       5.563   Cond. No.                     1.40e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 1, 3, 4, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 08 Apr 2018</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:20:07</td>     <th>  Log-Likelihood:    </th> <td> -755.64</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1519.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1527.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+06</td> <td> 6.57e+05</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+06</td> <td> 6.34e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+08</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Sun, 08 Apr 2018   Prob (F-statistic):           4.53e-30\n",
       "Time:                        23:20:07   Log-Likelihood:                -755.64\n",
       "No. Observations:                  50   AIC:                             1519.\n",
       "Df Residuals:                      46   BIC:                             1527.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+06   6.57e+05      7.626      0.000    3.69e+06    6.34e+06\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 3, 4, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 08 Apr 2018</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:20:07</td>     <th>  Log-Likelihood:    </th> <td> -755.79</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1518.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1523.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+06</td> <td> 2.69e+05</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+06</td> <td> 5.24e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+07</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Sun, 08 Apr 2018   Prob (F-statistic):           2.16e-31\n",
       "Time:                        23:20:07   Log-Likelihood:                -755.79\n",
       "No. Observations:                  50   AIC:                             1518.\n",
       "Df Residuals:                      47   BIC:                             1523.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+06   2.69e+05     17.464      0.000    4.16e+06    5.24e+06\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+07\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 3, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 08 Apr 2018</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:20:07</td>     <th>  Log-Likelihood:    </th> <td> -757.70</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1519.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1523.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.903e+06</td> <td> 2.54e+05</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+06</td> <td> 5.41e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+07</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     849.8\n",
       "Date:                Sun, 08 Apr 2018   Prob (F-statistic):           3.50e-32\n",
       "Time:                        23:20:07   Log-Likelihood:                -757.70\n",
       "No. Observations:                  50   AIC:                             1519.\n",
       "Df Residuals:                      48   BIC:                             1523.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.903e+06   2.54e+05     19.320      0.000    4.39e+06    5.41e+06\n",
       "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
       "==============================================================================\n",
       "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
       "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
       "Kurtosis:                       5.361   Cond. No.                     1.65e+07\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.65e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 3]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
